{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando bibliotecas\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "    \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'UCI'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPC SSL Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de Treino\n",
    "\n",
    "data_path = Path(f'/workspaces/betania.silva/view_concatenated/{DATASET_NAME}/train')\n",
    "\n",
    "datas_x_train = []\n",
    "\n",
    "data_y_train = []\n",
    "\n",
    "for f in data_path.glob('*.csv'):\n",
    "    data = pd.read_csv(f)\n",
    "    x = data[['accel-x', 'accel-y', 'accel-z', 'gyro-x', 'gyro-y', 'gyro-z']].values\n",
    "\n",
    "    # Expend dimension\n",
    "\n",
    "    x = np.swapaxes(x, 1, 0)\n",
    "    \n",
    "    datas_x_train.append(x)\n",
    "\n",
    "    y = data['standard activity code'].values\n",
    "\n",
    "    data_y_train.append(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de Teste\n",
    "\n",
    "data_path = Path(f'/workspaces/betania.silva/view_concatenated/{DATASET_NAME}/test')\n",
    "\n",
    "datas_x_test = []\n",
    "\n",
    "data_y_test = []\n",
    "\n",
    "for f in data_path.glob('*.csv'):\n",
    "    data = pd.read_csv(f)\n",
    "    x = data[['accel-x', 'accel-y', 'accel-z', 'gyro-x', 'gyro-y', 'gyro-z']].values\n",
    "\n",
    "    # Expend dimension\n",
    "\n",
    "    x = np.swapaxes(x, 1, 0)\n",
    "    \n",
    "    datas_x_test.append(x)\n",
    "\n",
    "    y = data['standard activity code'].values\n",
    "\n",
    "    data_y_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = datas_x_train\n",
    "y_train = data_y_train\n",
    "x_test = datas_x_test\n",
    "y_test = data_y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume todos os vetores z em em único vetor de contexto​\n",
    "\n",
    "class GRUEncoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int = 100,\n",
    "        in_channel: int = 561,\n",
    "        encoding_size: int = 10,\n",
    "        num_layers: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "        bidirectional: bool = True,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in_channel = in_channel\n",
    "        self.num_layers = num_layers\n",
    "        self.encoding_size = encoding_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.device = device\n",
    "        \n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size=self.in_channel,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=False,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional,\n",
    "        ).to(device) \n",
    "\n",
    "        self.nn = torch.nn.Linear(\n",
    "            self.hidden_size * (int(self.bidirectional) + 1), self.encoding_size\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(2, 0, 1)\n",
    "        print(x.size())\n",
    "\n",
    "        past = torch.zeros(\n",
    "            self.num_layers * (int(self.bidirectional) + 1),\n",
    "            x.shape[1],\n",
    "            self.hidden_size,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        out, _ = self.rnn(\n",
    "            x, past\n",
    "        )  # out shape = [seq_len, batch_size, num_directions*hidden_size]\n",
    "        encodings = self.nn(out[-1].squeeze(0))\n",
    "\n",
    "        return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPC(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: torch.nn.Module,\n",
    "        density_estimator: torch.nn.Module,\n",
    "        auto_regressor: torch.nn.Module,\n",
    "        lr: float = 1e-3,\n",
    "        weight_decay: float = 0.0,\n",
    "        window_size: int = 4,\n",
    "        n_size: int = 5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(self.device)\n",
    "        self.density_estimator = density_estimator.to(self.device)\n",
    "        self.auto_regressor = auto_regressor.to(self.device)\n",
    "        self.learning_rate = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.window_size = window_size\n",
    "        self.n_size = n_size\n",
    "        self.training_step_losses = []\n",
    "        self.best_train_loss = float('inf')\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        print(\"AAAAAAAprint BATCH\", batch.size())\n",
    "        assert len(batch) == 1, \"Batch must be 1 sample only\"\n",
    "        sample = batch\n",
    "        sample = sample.squeeze(0)\n",
    "        rnd_t = np.random.randint(\n",
    "            5 * self.window_size, sample.shape[-1] - 5 * self.window_size\n",
    "        )\n",
    "        sample = torch.tensor(\n",
    "            sample[\n",
    "                :,\n",
    "                max(0, (rnd_t - 20 * self.window_size)) : min(\n",
    "                    sample.shape[-1], rnd_t + 20 * self.window_size\n",
    "                ),\n",
    "            ]\n",
    "        ).cpu()\n",
    "\n",
    "        T = sample.shape[-1]\n",
    "        windowed_sample = np.split(\n",
    "            sample[:, : (T // self.window_size) * self.window_size],\n",
    "            (T // self.window_size),\n",
    "            -1,\n",
    "        )\n",
    "        windowed_sample = torch.tensor(np.stack(windowed_sample, 0), device=self.device)\n",
    "        \n",
    "        encodings = self.encoder(windowed_sample)\n",
    "\n",
    "        print(\"encoding_size\", encodings.size())\n",
    "\n",
    "        window_ind = torch.randint(2, len(encodings) - 2, size=(1,))\n",
    "\n",
    "        print(\"window_ind\", window_ind)\n",
    "        \n",
    "        _, c_t = self.auto_regressor(\n",
    "            encodings[max(0, window_ind[0] - 10) : window_ind[0] + 1].unsqueeze(0)\n",
    "        )\n",
    "\n",
    "        print(\"CT:\", c_t.size())\n",
    "        \n",
    "        ab = self.density_estimator(c_t)\n",
    "\n",
    "        print(\"density_estimator\", ab.size())\n",
    "\n",
    "        density_ratios = torch.bmm(\n",
    "            encodings.unsqueeze(1),\n",
    "            self.density_estimator(c_t.squeeze(1).squeeze(0)).expand_as(encodings).unsqueeze(-1),\n",
    "        ).view(\n",
    "            -1,\n",
    "        )\n",
    "        print(\"encoding size\", encodings.unsqueeze(1).size())\n",
    "        print(\"density_estimator size\", self.density_estimator(c_t.squeeze(1).squeeze(0)).expand_as(encodings).unsqueeze(-1).size())\n",
    "        r = set(range(0, window_ind[0] - 2))\n",
    "        r.update(set(range(window_ind[0] + 3, len(encodings))))\n",
    "        rnd_n = np.random.choice(list(r), self.n_size)\n",
    "        X_N = torch.cat(\n",
    "            [density_ratios[rnd_n], density_ratios[window_ind[0] + 1].unsqueeze(0)], 0\n",
    "        )\n",
    "        labels = torch.Tensor([len(X_N) - 1]).to(self.device)\n",
    "        loss = torch.nn.CrossEntropyLoss()(X_N.view(1, -1), labels.long())\n",
    "        if loss < self.best_train_loss:\n",
    "            self.best_train_loss = loss\n",
    "        self.training_step_losses.append(loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        # do something with all training_step outputs, for example:\n",
    "        epoch_mean = torch.stack(self.training_step_losses).mean()\n",
    "        self.log(\"train_loss\", epoch_mean, on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "        if epoch_mean < self.best_train_loss:\n",
    "            self.best_train_loss = epoch_mean\n",
    "            self.log(\"best_train_loss\", self.best_train_loss, on_epoch=True, on_step=False, prog_bar=False, logger=True)\n",
    "        # free up the memory\n",
    "        self.training_step_losses.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        learnable_parameters = (\n",
    "            list(self.density_estimator.parameters())\n",
    "            + list(self.encoder.parameters())\n",
    "            + list(self.auto_regressor.parameters())\n",
    "        )\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            learnable_parameters, lr=self.learning_rate, weight_decay=self.weight_decay\n",
    "        )\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma instância do ModelCheckpoint para salvar nos pontos de verificação correspondentes à perda mínima\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filename='best_model',\n",
    "    monitor='train_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    save_last=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 6\n",
    "encoding_size = 10\n",
    "\n",
    "encoder = GRUEncoder(in_channel=6, encoding_size = 10, device='cpu')\n",
    "density_estimator = torch.nn.Linear(encoding_size, encoding_size)\n",
    "auto_regressor = torch.nn.GRU(\n",
    "    input_size=encoding_size, \n",
    "    hidden_size=encoding_size, \n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "cpc = CPC(encoder, density_estimator, auto_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 6)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleDataset:\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx].astype(np.float32), self.y[idx].astype(np.float32)\n",
    "        else:\n",
    "            return self.X[idx].astype(np.float32)\n",
    "    \n",
    "train_dataset = SimpleDataset(x_train)\n",
    "test_dataset = SimpleDataset(x_test, y_test)\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, num_workers=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, num_workers=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/betania_meta4/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=2, accelerator=\"cpu\", devices=1, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | encoder           | GRUEncoder | 66.8 K\n",
      "1 | density_estimator | Linear     | 110   \n",
      "2 | auto_regressor    | GRU        | 660   \n",
      "-------------------------------------------------\n",
      "67.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "67.6 K    Total params\n",
      "0.270     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/betania_meta4/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49de9f897ab4de3ba408307ee9b8695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3699626/1042588862.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAprint BATCH torch.Size([1, 6, 7762])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([27])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 9130])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([9])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7040])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([32])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8073])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([17])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7671])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([10])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8824])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([26])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 9127])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([9])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8771])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([3])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8449])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([23])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7417])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([35])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8194])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([36])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7485])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([2])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8632])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([21])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8726])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([8])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8041])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([13])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8422])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 21: 'train_loss' reached 1.79274 (best 1.79274), saving model to '/workspaces/betania.silva/ssl_tools/cpc_notebooks_test/lightning_logs/version_488/checkpoints/best_model.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 9541])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([29])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7385])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([6])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7826])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([22])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7615])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([13])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7935])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([15])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7671])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([29])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8422])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([26])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7826])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([19])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7762])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([19])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 9130])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([16])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8726])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([30])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8073])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([9])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8194])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([29])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7385])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([14])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 9127])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([30])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8041])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([37])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8771])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([13])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7485])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([14])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7040])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([36])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7615])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([2])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8449])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([7])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7417])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([5])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 7935])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([29])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8632])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([13])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 8824])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([33])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n",
      "AAAAAAAprint BATCH torch.Size([1, 6, 9541])\n",
      "torch.Size([4, 40, 6])\n",
      "encoding_size torch.Size([40, 10])\n",
      "window_ind tensor([3])\n",
      "CT: torch.Size([1, 1, 10])\n",
      "density_estimator torch.Size([1, 1, 10])\n",
      "encoding size torch.Size([40, 1, 10])\n",
      "density_estimator size torch.Size([40, 10, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 42: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(cpc, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspaces/betania/ssl_tools/cpc/lightning_logs/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspaces/betania/ssl_tools/cpc/lightning_logs/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Lista todas as versões no diretório\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m all_versions \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, d)) \u001b[38;5;129;01mand\u001b[39;00m d\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ordena as versões em ordem decrescente\u001b[39;00m\n\u001b[1;32m     11\u001b[0m sorted_versions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(all_versions, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]), reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/workspaces/betania/ssl_tools/cpc/lightning_logs/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Diretório onde os checkpoints estão salvos\n",
    "checkpoint_dir = '/workspaces/betania/ssl_tools/cpc/lightning_logs/'\n",
    "\n",
    "# Lista todas as versões no diretório\n",
    "all_versions = [d for d in os.listdir(checkpoint_dir) if os.path.isdir(os.path.join(checkpoint_dir, d)) and d.startswith('version_')]\n",
    "\n",
    "# Ordena as versões em ordem decrescente\n",
    "sorted_versions = sorted(all_versions, key=lambda x: int(x.split('_')[1]), reverse=True)\n",
    "\n",
    "# Obtém a versão mais recente\n",
    "latest_version = sorted_versions[0]\n",
    "\n",
    "VERSION = latest_version\n",
    "\n",
    "# Crie uma instância do modelo\n",
    "\n",
    "cpc = CPC(encoder, density_estimator, auto_regressor)\n",
    "\n",
    "# Carregue os pesos salvos no ponto de verificação 'best_model.ckpt' para o cpc\n",
    "\n",
    "# Mudando a versão do checkpoint\n",
    "\n",
    "checkpoint_path = f'/workspaces/betania/ssl_tools/cpc/lightning_logs/{VERSION}/checkpoints/best_model.ckpt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Carregue os pesos no seu modelo\n",
    "cpc.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPC(\n",
       "  (encoder): GRUEncoder(\n",
       "    (rnn): GRU(6, 100, bidirectional=True)\n",
       "    (nn): Linear(in_features=200, out_features=10, bias=True)\n",
       "  )\n",
       "  (density_estimator): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (auto_regressor): GRU(10, 10, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpc.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPC Fine-Tuning\n",
    "\n",
    "We are going to fine-tune the CPC model on the downstream task of classification. We will use the same dataset and re-use the same encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "# Classificando com uma MLP\n",
    "\n",
    "class StateClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size: int= 10, hidden_size1= 64, hidden_size2=64, num_classes= 7, dropout_prob= 0):\n",
    "        super(StateClassifier, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(hidden_size1, hidden_size2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size2, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out\n",
    "\n",
    " #Linear\n",
    "    \n",
    "# class StateClassifier(torch.nn.Module):\n",
    "#     def __init__(self, input_size: int = 10, n_classes: int = 7):\n",
    "#         super(StateClassifier, self).__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.n_classes = n_classes\n",
    "#         self.normalize = torch.nn.BatchNorm1d(self.input_size)\n",
    "#         self.nn = torch.nn.Linear(self.input_size, self.n_classes)\n",
    "#         torch.nn.init.xavier_uniform_(self.nn.weight)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.normalize(x)\n",
    "#         logits = self.nn(x)\n",
    "#         return logits\n",
    "\n",
    "class CPC_Classifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: torch.nn.Module,\n",
    "        classifier: torch.nn.Module,\n",
    "        lr: float = 1e-3,\n",
    "        weight_decay: float = 0.0,\n",
    "        task_class: str = \"multiclass\",\n",
    "        num_classes: int = 7\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(self.device)\n",
    "        self.classifier = classifier.to(self.device)\n",
    "        self.learning_rate = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.training_step_losses = []\n",
    "        self.validation_step_losses = []\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "        self.task_class = task_class\n",
    "        self.num_classes = num_classes\n",
    "        self.best_validation_loss = float('inf')\n",
    "        \n",
    "    def configure_optimizers(self) -> Any:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.classifier.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay\n",
    "        )\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encodings = self.encoder(x)\n",
    "        predictions = self.classifier(encodings)\n",
    "        return predictions\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        loss = self.loss_function(predictions, y.long())\n",
    "        self.training_step_losses.append(loss)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        # do something with all training_step outputs, for example:\n",
    "        epoch_mean = torch.stack(self.training_step_losses).mean()\n",
    "        self.log(\"train_loss\", epoch_mean, on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "        # free up the memory\n",
    "        self.training_step_losses.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        if loss < self.best_validation_loss:\n",
    "            self.best_validation_loss = loss\n",
    "        self.validation_step_losses.append(loss)\n",
    "        metrics = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        metrics = {\"test_acc\": acc, \"test_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n",
    "        \n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        # do something with all training_step outputs, for example:\n",
    "        epoch_mean = torch.stack(self.validation_step_losses).mean()\n",
    "        self.log(\"val_loss\", epoch_mean, on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "        if epoch_mean < self.best_validation_loss:\n",
    "            self.best_validation_loss = epoch_mean\n",
    "            self.log(\"best_validation_loss\", self.best_validation_loss, on_epoch=True, on_step=False, prog_bar=False, logger=True)\n",
    "        # free up the memory\n",
    "        self.validation_step_losses.clear()\n",
    "\n",
    "    def _shared_eval_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        loss = self.loss_function(predictions, y.long())\n",
    "        acc = accuracy(torch.argmax(predictions, dim=1), y.long(), task=self.task_class, num_classes=self.num_classes)\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename='best_model',\n",
    "    monitor='val_loss',  # escolha a métrica que você deseja monitorar (pode ser 'val_acc' ou outra métrica)\n",
    "    mode='min',  # 'min' significa que queremos minimizar a métrica monitorada (por exemplo, perda)\n",
    "    save_top_k=1,  # salva apenas o melhor modelo\n",
    "    save_last=False,  # salva o último modelo\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Caminho dos dados\n",
    "\n",
    "data_path_train = Path(f'/workspaces/betania/data/standartized_balanced/{DATASET_NAME}/train.csv')\n",
    "\n",
    "data_path_validation = Path(f'/workspaces/betania/data/standartized_balanced/{DATASET_NAME}/validation.csv')\n",
    "\n",
    "data_path_test = Path(f'/workspaces/betania/data/standartized_balanced/{DATASET_NAME}/test.csv')\n",
    "\n",
    "# Train\n",
    "\n",
    "x_train = pd.read_csv(data_path_train)\n",
    "\n",
    "x_train = x_train.iloc[:, :360]\n",
    "    \n",
    "x_train = x_train.astype(np.float32)\n",
    "\n",
    "y_train = pd.read_csv(data_path_train)\n",
    "\n",
    "y_train = y_train.iloc[:, -1]\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "\n",
    "tensor_x = torch.Tensor(np.array(x_train))\n",
    "\n",
    "tensor_y = torch.Tensor(np.array(y_train))\n",
    "\n",
    "original_dim = tensor_x.shape[0]\n",
    "\n",
    "input_shape = (original_dim, 6, 60)\n",
    "\n",
    "tensor_x = tensor_x.reshape(input_shape)\n",
    "\n",
    "dataset_train= TensorDataset(tensor_x,tensor_y)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, drop_last= True)\n",
    "\n",
    "# Validation\n",
    "\n",
    "x_validation = pd.read_csv(data_path_validation)\n",
    "\n",
    "x_validation = x_validation.iloc[:, :360]\n",
    "\n",
    "x_validation = x_validation.astype(np.float32)\n",
    "\n",
    "y_validation = pd.read_csv(data_path_validation)\n",
    "\n",
    "y_validation = y_validation.iloc[:, -1]\n",
    "\n",
    "y_validation = y_validation.astype(np.float32)\n",
    "\n",
    "tensor_x_val = torch.Tensor(np.array(x_validation))\n",
    "\n",
    "tensor_y_val = torch.Tensor(np.array(y_validation))\n",
    "\n",
    "original_dim_val = tensor_x_val.shape[0]\n",
    "\n",
    "tensor_x_val = tensor_x_val.reshape(original_dim_val, 6, 60)\n",
    "\n",
    "dataset_val= TensorDataset(tensor_x_val,tensor_y_val)\n",
    "\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "\n",
    "# Test\n",
    "\n",
    "x_test = pd.read_csv(data_path_test)\n",
    "\n",
    "x_test = x_test.iloc[:, :360]\n",
    "\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "y_test = pd.read_csv(data_path_test)\n",
    "\n",
    "y_test = y_test.iloc[:, -1]\n",
    "\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "tensor_x_test = torch.Tensor(np.array(x_test))\n",
    "\n",
    "tensor_y_test = torch.Tensor(np.array(y_test))\n",
    "\n",
    "original_dim_test = tensor_x_test.shape[0]\n",
    "\n",
    "tensor_x_test = tensor_x_test.reshape((original_dim_test, 6, 60))\n",
    "\n",
    "dataset_test= TensorDataset(tensor_x_test,tensor_y_test)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True, drop_last= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_size = 10\n",
    "n_classes = 7\n",
    "\n",
    "\n",
    "#classifier = StateClassifier(input_size=encoding_size, n_classes=n_classes)\n",
    "\n",
    "classifier = StateClassifier(input_size=encoding_size, num_classes=n_classes, dropout_prob=0, hidden_size1= 64, hidden_size2=32)\n",
    "cpc_classifier = CPC_Classifier(encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_classifier = cpc_classifier.to('cuda')\n",
    "\n",
    "# Forward no conjunto de teste\n",
    "with torch.no_grad():\n",
    "    xtest = cpc_classifier.forward(tensor_x_test.to('cuda')).cpu().numpy()\n",
    "\n",
    "# Forward no conjunto de treinamento\n",
    "with torch.no_grad():\n",
    "    xtrain = cpc_classifier.forward(tensor_x.to('cuda')).cpu().numpy()\n",
    "\n",
    "# Converter rótulos para NumPy\n",
    "ytrain = tensor_y.cpu().numpy()\n",
    "ytest = tensor_y_test.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A precisão do modelo no conjunto de teste é: 0.5579710144927537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "random_forest_model.fit(xtrain, ytrain)\n",
    "\n",
    "# Faça previsões no conjunto de teste\n",
    "predictions = random_forest_model.predict(xtest)\n",
    "\n",
    "# Avalie o desempenho do modelo usando métricas, como a precisão\n",
    "accuracy = accuracy_score(ytest, predictions)\n",
    "\n",
    "print(f'A precisão do modelo no conjunto de teste é: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (KNN): 0.5420289855072464\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Criar o modelo KNN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=20)  # Pode ajustar o número de vizinhos conforme necessário\n",
    "\n",
    "# Treinar o modelo\n",
    "knn_model.fit(xtrain, ytrain)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "predictions_knn = knn_model.predict(xtest)\n",
    "\n",
    "# Avaliar o desempenho do modelo usando métricas, como a precisão\n",
    "accuracy_knn = accuracy_score(ytest, predictions_knn)\n",
    "\n",
    "print(\"Accuracy (KNN):\", accuracy_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (SVM): 0.3101449275362319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Criar o modelo SVM\n",
    "svm_model = SVC(kernel='linear', C=1.0)  # Pode ajustar o kernel e C conforme necessário\n",
    "\n",
    "# Treinar o modelo\n",
    "svm_model.fit(xtrain, ytrain)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "predictions_svm = svm_model.predict(xtest)\n",
    "\n",
    "# Avaliar o desempenho do modelo usando métricas, como a precisão\n",
    "accuracy_svm = accuracy_score(ytest, predictions_svm)\n",
    "\n",
    "print(\"Accuracy (SVM):\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer = pl.Trainer(max_epochs=300, accelerator=\"gpu\", devices=1, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.fit(cpc_classifier, train_dataloaders=dataloader_train, val_dataloaders=dataloader_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CPC_Classifier:\n\tMissing key(s) in state_dict: \"classifier.layer1.0.weight\", \"classifier.layer1.0.bias\", \"classifier.layer2.0.weight\", \"classifier.layer2.0.bias\", \"classifier.output_layer.0.weight\", \"classifier.output_layer.0.bias\". \n\tUnexpected key(s) in state_dict: \"density_estimator.weight\", \"density_estimator.bias\", \"auto_regressor.weight_ih_l0\", \"auto_regressor.weight_hh_l0\", \"auto_regressor.bias_ih_l0\", \"auto_regressor.bias_hh_l0\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(checkpoint_path, map_location\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[39m# Carregue os pesos no seu classificador\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m cpc_classifier\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m'\u001b[39;49m\u001b[39mstate_dict\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:2056\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2052\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2053\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2056\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2057\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2058\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CPC_Classifier:\n\tMissing key(s) in state_dict: \"classifier.layer1.0.weight\", \"classifier.layer1.0.bias\", \"classifier.layer2.0.weight\", \"classifier.layer2.0.bias\", \"classifier.output_layer.0.weight\", \"classifier.output_layer.0.bias\". \n\tUnexpected key(s) in state_dict: \"density_estimator.weight\", \"density_estimator.bias\", \"auto_regressor.weight_ih_l0\", \"auto_regressor.weight_hh_l0\", \"auto_regressor.bias_ih_l0\", \"auto_regressor.bias_hh_l0\". "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Diretório onde os checkpoints estão salvos\n",
    "checkpoint_dir = '/workspaces/betania/ssl_tools/cpc/lightning_logs/'\n",
    "\n",
    "# Lista todas as versões no diretório\n",
    "all_versions = [d for d in os.listdir(checkpoint_dir) if os.path.isdir(os.path.join(checkpoint_dir, d)) and d.startswith('version_')]\n",
    "\n",
    "# Ordena as versões em ordem decrescente\n",
    "sorted_versions = sorted(all_versions, key=lambda x: int(x.split('_')[1]), reverse=True)\n",
    "\n",
    "# Obtém a versão mais recente\n",
    "latest_version = sorted_versions[0]\n",
    "\n",
    "VERSION = latest_version\n",
    "\n",
    "# Carregue os pesos salvos no ponto de verificação 'best_model.ckpt' para o cpc\n",
    "\n",
    "# Mudando a versão do checkpoint\n",
    "\n",
    "checkpoint_path = f'/workspaces/betania/ssl_tools/cpc/lightning_logs/{VERSION}/checkpoints/best_model.ckpt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Carregue os pesos no seu classificador\n",
    "cpc_classifier.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/vscode/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/vscode/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 6/6 [00:00<00:00, 75.09it/s] \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc             0.621666669845581\n",
      "        test_loss            1.544309377670288\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.621666669845581, 'test_loss': 1.544309377670288}]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(cpc_classifier, dataloader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
